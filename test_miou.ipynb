{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713527878"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from config import get_opts\n",
    "from models.ngp_wrapper import NGP_Prop_Art_Wrapper, NGP_Prop_Wrapper, NGP_Prop_Art_Seg_Wrapper\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.sapien import SapienParisDataset\n",
    "from tqdm import tqdm\n",
    "import open3d as o3d\n",
    "import sys\n",
    "import traceback\n",
    "from pose_estimation import PoseEstimator_multipart\n",
    "from test_ngp import NGPevaluator\n",
    "from dataset.pose_utils import quaternion_to_axis_angle, get_rotation_axis_angle\n",
    "from dataset.io_utils import load_gt_from_json, load_multipart_gt\n",
    "from models.utils import axis_metrics, geodesic_distance, translational_error\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "from pathlib import Path as P\n",
    "import torchvision.transforms.functional as tvF\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# stapler_path = P(\"./results_stable/stapler_end_to_start_f16/1713970094\")\n",
    "# fridge_path = P(\"./results_stable/fridge_end_to_start_f16/1713977542\")\n",
    "# laptop_path = P(\"./results_stable/laptop_start_to_end_f16/1713997073\")\n",
    "# oven_path = P(\"./results_stable/oven_start_to_end_f16/1713998823\")\n",
    "# scissor_path = P(\"./results_stable/scissor_end_to_start_f16/1714000996\")\n",
    "\n",
    "# # prismatic\n",
    "# storage_path = P(\"./results_stable/storage_end_to_start_f16/1714002072\")\n",
    "# blade_path = P(\"./results_stable/blade_start_to_end_f16/1714009298\")\n",
    "\n",
    "\n",
    "\n",
    "stapler_path = P(\"./results_ablation/stapler_end_to_start_f100/\")\n",
    "fridge_path = P(\"./results_ablation/fridge_end_to_start_f100/\")\n",
    "laptop_path = P(\"./results_ablation/laptop_start_to_end_f100/\")\n",
    "oven_path = P(\"./results_ablation/oven_start_to_end_f100/\")\n",
    "scissor_path = P(\"./results_ablation/scissor_end_to_start_f100/\")\n",
    "\n",
    "# prismatic\n",
    "storage_path = P(\"./results_ablation/storage_end_to_start_f100/\")\n",
    "blade_path = P(\"./results_ablation/blade_start_to_end_f100/\")\n",
    "\n",
    "# path_list = [stapler_path, fridge_path, laptop_path, oven_path, scissor_path, storage_path, blade_path]\n",
    "# path_list = [oven_path, scissor_path, storage_path]\n",
    "path_list = [scissor_path]\n",
    "# box\n",
    "box_path = P(\"./results_stable/box_start_to_end_f16/1714063616\")\n",
    "glasses_path = P(\"./results_stable/glasses_end_to_start_f16/1714068462\")\n",
    "oven_mp_path = P(\"./results_ablation/oven_mp_start_to_end_f100/1715607722\")\n",
    "\n",
    "1713527878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating at path: results_ablation/scissor_end_to_start_f100/1714839015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:38,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_ablation/scissor_end_to_start_f100/1714839015/test/0000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:01<00:36,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_ablation/scissor_end_to_start_f100/1714839015/test/0001.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:02<00:34,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_ablation/scissor_end_to_start_f100/1714839015/test/0002.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:02<00:33,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_ablation/scissor_end_to_start_f100/1714839015/test/0003.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:03<00:32,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_ablation/scissor_end_to_start_f100/1714839015/test/0004.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:04<00:32,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_ablation/scissor_end_to_start_f100/1714839015/test/0005.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:05<00:32,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_ablation/scissor_end_to_start_f100/1714839015/test/0006.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(test_dataset\u001b[38;5;241m.\u001b[39mposes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m     49\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m test_dataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(idx)\n\u001b[0;32m---> 50\u001b[0m     render_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     seg_pred \u001b[38;5;241m=\u001b[39m render_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     52\u001b[0m     seg_bg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(seg_pred[:, :, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/djn/anaconda3/envs/art_ngp/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/scratch/djn/nerf/models/ngp_wrapper.py:2491\u001b[0m, in \u001b[0;36mNGP_Prop_Art_Seg_Wrapper.test\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;66;03m# pixels = data[\"pixels\"].to(self.device)\u001b[39;00m\n\u001b[1;32m   2487\u001b[0m \n\u001b[1;32m   2488\u001b[0m \u001b[38;5;66;03m# duplicate rays\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m rays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_rays(dirs, c2w)\n\u001b[0;32m-> 2491\u001b[0m rgb, acc, depth, extras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_whole_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_bkgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_bkgd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2492\u001b[0m h, w, _ \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrays\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39morigins\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   2493\u001b[0m rgb \u001b[38;5;241m=\u001b[39m rgb\u001b[38;5;241m.\u001b[39mview(h, w, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/disk/scratch/djn/nerf/models/ngp_wrapper.py:2322\u001b[0m, in \u001b[0;36mNGP_Prop_Art_Seg_Wrapper.render_whole_img\u001b[0;34m(self, rays, render_bkgd)\u001b[0m\n\u001b[1;32m   2320\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_rays, chunk):\n\u001b[1;32m   2321\u001b[0m     chunk_rays \u001b[38;5;241m=\u001b[39m namedtuple_map(\u001b[38;5;28;01mlambda\u001b[39;00m r: r[i : i \u001b[38;5;241m+\u001b[39m chunk], rays)\n\u001b[0;32m-> 2322\u001b[0m     rgb, opacity, depth, extras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_rays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_rays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_bkgd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_bkgd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mngp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mngp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2324\u001b[0m     chunk_out \u001b[38;5;241m=\u001b[39m [rgb, opacity, depth]\n\u001b[1;32m   2325\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(chunk_out)\n",
      "File \u001b[0;32m/disk/scratch/djn/nerf/models/ngp_wrapper.py:2220\u001b[0m, in \u001b[0;36mNGP_Prop_Art_Seg_Wrapper.render_rays\u001b[0;34m(self, rays, render_bkgd, ngp, estimator, proposal_requires_grad, test_chunk_size)\u001b[0m\n\u001b[1;32m   2217\u001b[0m         sigmas[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m   2218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rgb, sigmas\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2220\u001b[0m t_starts, t_ends \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseg_sampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprop_sigma_fns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprop_sigma_seg_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproposal_networks\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprop_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples_per_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_rays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrays\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnear_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfar_plane\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfar_plane\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstratified\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproposal_requires_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_background\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_background\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseg_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseg_classes\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomposite_rendering\u001b[39m(t_starts, t_ends):\n\u001b[1;32m   2237\u001b[0m     dist \u001b[38;5;241m=\u001b[39m t_ends \u001b[38;5;241m-\u001b[39m t_starts\n",
      "File \u001b[0;32m~/djn/anaconda3/envs/art_ngp/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/disk/scratch/djn/nerf/models/ngp_wrapper.py:370\u001b[0m, in \u001b[0;36mPropArtEstimator.seg_sampling\u001b[0;34m(self, prop_sigma_fns, prop_samples, num_samples, n_rays, near_plane, far_plane, seg_classes, sampling_type, stratified, requires_grad, use_background)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprop_cache\u001b[38;5;241m.\u001b[39mappend((intervals, seg_cdfs))\n\u001b[1;32m    367\u001b[0m intervals, _ \u001b[38;5;241m=\u001b[39m importance_sampling(\n\u001b[1;32m    368\u001b[0m     intervals, cdfs, num_samples, stratified\n\u001b[1;32m    369\u001b[0m )\n\u001b[0;32m--> 370\u001b[0m t_vals \u001b[38;5;241m=\u001b[39m \u001b[43m_transform_stot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintervals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnear_plane\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfar_plane\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m t_starts \u001b[38;5;241m=\u001b[39m t_vals[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    374\u001b[0m t_ends \u001b[38;5;241m=\u001b[39m t_vals[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/djn/anaconda3/envs/art_ngp/lib/python3.9/site-packages/nerfacc/estimators/prop_net.py:229\u001b[0m, in \u001b[0;36m_transform_stot\u001b[0;34m(transform_type, s_vals, t_min, t_max)\u001b[0m\n\u001b[1;32m    227\u001b[0m s_min, s_max \u001b[38;5;241m=\u001b[39m _contract_fn(t_min), _contract_fn(t_max)\n\u001b[1;32m    228\u001b[0m icontract_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s: _icontract_fn(s \u001b[38;5;241m*\u001b[39m s_max \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m s) \u001b[38;5;241m*\u001b[39m s_min)\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43micontract_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_vals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/djn/anaconda3/envs/art_ngp/lib/python3.9/site-packages/nerfacc/estimators/prop_net.py:228\u001b[0m, in \u001b[0;36m_transform_stot.<locals>.<lambda>\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown transform_type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransform_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m s_min, s_max \u001b[38;5;241m=\u001b[39m _contract_fn(t_min), _contract_fn(t_max)\n\u001b[0;32m--> 228\u001b[0m icontract_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s: _icontract_fn(s \u001b[38;5;241m*\u001b[39m s_max \u001b[38;5;241m+\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms_min\u001b[49m)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m icontract_fn(s_vals)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "ckpt_path = stapler_path\n",
    "for obj_path in path_list:\n",
    "    mious = []\n",
    "    ckpt_paths = obj_path.glob('*')\n",
    "    \n",
    "    for ckpt_path in ckpt_paths:\n",
    "        \n",
    "        print(f'evaluating at path: {str(ckpt_path)}')\n",
    "        config_file = ckpt_path / 'eval' / 'config.json'\n",
    "        if not config_file.exists():\n",
    "            continue\n",
    "        config_argv = ['--config', str(config_file)]\n",
    "        opts = get_opts(config_argv)\n",
    "        if torch.cuda.is_available():\n",
    "            device = 'cuda'\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "\n",
    "        setattr(opts, 'device', device)\n",
    "\n",
    "        color_map = plt.get_cmap('Set3', 5)\n",
    "        cmap = color_map.colors[:, :3]\n",
    "        cmap[0, :] = 0\n",
    "\n",
    "        opts.pre_trained_weights = str(ckpt_path / 'ckpt' / 'best_ckpt.pth')\n",
    "        if opts.state == 'start':\n",
    "            opts.state = 'end'\n",
    "        else:\n",
    "            opts.state = 'start'\n",
    "        model = NGP_Prop_Art_Seg_Wrapper(config=opts, training=False, \n",
    "                                        ignore_empty=False, use_timestamp=True, use_se3=opts.use_se3, mkdir=False)\n",
    "        test_dir = model.output_path / 'test'\n",
    "        test_dir.mkdir(exist_ok=True)\n",
    "        test_dataset = SapienParisDataset(\n",
    "                root_dir = opts.root_dir,\n",
    "                near = opts.near_plane,\n",
    "                far = opts.far_plane,\n",
    "                img_wh = opts.img_wh, \n",
    "                batch_size=opts.batch_size,\n",
    "                split='test',\n",
    "                render_bkgd='white',\n",
    "                state=opts.state\n",
    "            )\n",
    "\n",
    "        ious = []\n",
    "        for p in model.pose_module_list:\n",
    "            p.init_param()\n",
    "        for idx in tqdm(range(test_dataset.poses.shape[0])):\n",
    "            batch_data = test_dataset.__getitem__(idx)\n",
    "            render_batch = model.test(batch_data)\n",
    "            seg_pred = render_batch['seg_label']\n",
    "            seg_bg = torch.ones_like(seg_pred[:, :, 0:1])\n",
    "            seg_bg = seg_bg - seg_pred.sum(dim=-1, keepdim=True)\n",
    "            seg_pred_bg = torch.cat([seg_bg, seg_pred], dim=-1)\n",
    "            seg_classes = torch.argmax(seg_pred_bg, dim=-1, keepdim=True)\n",
    "            seg_classes_np = seg_classes.cpu().numpy()\n",
    "            test_img_name = str(test_dir / (str(idx).zfill(4) + '.png'))\n",
    "            \n",
    "            # np.save(test_seg_name, seg_classes_np)\n",
    "            gt_img = str(test_dir / (str(idx).zfill(4) + '_gt.png'))\n",
    "            cur_gt = test_dataset.seg[idx] * 255\n",
    "            \n",
    "            if 'stapler' in str(ckpt_path):\n",
    "                cur_gt = cur_gt - 1\n",
    "                cur_gt[cur_gt == 3] = 2\n",
    "            if 'oven' in str(ckpt_path):\n",
    "                cur_gt[(cur_gt < 9) & (cur_gt > 1)] = 1\n",
    "                cur_gt[cur_gt == 9] = 2\n",
    "            if P(test_dataset.root_dir).parent.name == 'storage':\n",
    "                cur_gt = cur_gt - 1\n",
    "                cur_gt[cur_gt == 2] = 1\n",
    "                cur_gt[cur_gt == 3] = 1\n",
    "                cur_gt[cur_gt == 4] = 2\n",
    "                cur_gt[cur_gt == 5] = 1\n",
    "            cur_gt[cur_gt < 0] = 0\n",
    "            seg_classes[cur_gt == 0] = 0\n",
    "            valid_pred = seg_classes[cur_gt != 0].view(-1)\n",
    "            valid_gt = cur_gt[cur_gt != 0].to(valid_pred).view(-1)\n",
    "            tp = (valid_pred == valid_gt).sum()\n",
    "            valid_sum = valid_gt.shape[0]\n",
    "            iou = tp/valid_sum\n",
    "            ious += [iou]\n",
    "            pred_seg_img = seg_classes.view(800, 800).cpu().numpy()\n",
    "            gt_seg_img = cur_gt.view(800, 800).cpu().numpy()\n",
    "            plt.imsave(test_img_name, cmap[pred_seg_img.astype(np.int16)])\n",
    "            print(test_img_name)\n",
    "            plt.imsave(gt_img, cmap[gt_seg_img.astype(np.int16)])\n",
    "        break\n",
    "    #     ious = torch.stack(ious)\n",
    "    #     # print(f'mIoU for ckpt: {ckpt_path}')\n",
    "    #     std, mean = torch.std_mean(ious, dim=0)\n",
    "    #     # print(f'mean: {mean.item()}, std: {std.item()}')\n",
    "    #     mious += [mean]\n",
    "    # mious = torch.stack(mious)\n",
    "    # stds, means = torch.std_mean(mious)\n",
    "    # print(f'evaluating at obj: {str(obj_path)}')\n",
    "    # print(f'mean: {means.item()}, std: {stds.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9906512498855591, std: 0.007663434371352196\n"
     ]
    }
   ],
   "source": [
    "std, mean = torch.std_mean(ious, dim=0)\n",
    "print(f'mean: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:42<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9889721870422363, std: 0.005943655967712402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ckpt_path = box_path\n",
    "\n",
    "config_file = ckpt_path / 'eval' / 'config.json'\n",
    "config_argv = ['--config', str(config_file)]\n",
    "opts = get_opts(config_argv)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "setattr(opts, 'device', device)\n",
    "\n",
    "color_map = plt.get_cmap('Set3', 5)\n",
    "cmap = color_map.colors[:, :3]\n",
    "cmap[0, :] = 0\n",
    "\n",
    "opts.pre_trained_weights = str(ckpt_path / 'ckpt' / 'best_ckpt.pth')\n",
    "if opts.state == 'start':\n",
    "    opts.state = 'end'\n",
    "else:\n",
    "    opts.state = 'start'\n",
    "model = NGP_Prop_Art_Seg_Wrapper(config=opts, training=False, \n",
    "                                ignore_empty=False, use_timestamp=True, use_se3=opts.use_se3, mkdir=False)\n",
    "test_dir = model.output_path / 'test'\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "test_dataset = SapienParisDataset(\n",
    "        root_dir = opts.root_dir,\n",
    "        near = opts.near_plane,\n",
    "        far = opts.far_plane,\n",
    "        img_wh = opts.img_wh, \n",
    "        batch_size=opts.batch_size,\n",
    "        split='test',\n",
    "        render_bkgd='white',\n",
    "        state=opts.state\n",
    "    )\n",
    "\n",
    "ious = []\n",
    "for p in model.pose_module_list:\n",
    "    p.init_param()\n",
    "for idx in tqdm(range(test_dataset.poses.shape[0])):\n",
    "    batch_data = test_dataset.__getitem__(idx)\n",
    "    render_batch = model.test(batch_data)\n",
    "    seg_pred = render_batch['seg_label']\n",
    "    seg_bg = torch.ones_like(seg_pred[:, :, 0:1])\n",
    "    seg_bg = seg_bg - seg_pred.sum(dim=-1, keepdim=True)\n",
    "    seg_pred_bg = torch.cat([seg_bg, seg_pred], dim=-1)\n",
    "    seg_classes = torch.argmax(seg_pred_bg, dim=-1, keepdim=True)\n",
    "    seg_classes_np = seg_classes.cpu().numpy()\n",
    "    test_img_name = str(test_dir / (str(idx).zfill(4) + '.png'))\n",
    "    \n",
    "    # np.save(test_seg_name, seg_classes_np)\n",
    "    gt_img = str(test_dir / (str(idx).zfill(4) + '_gt.png'))\n",
    "    cur_gt = test_dataset.seg[idx] * 255\n",
    "    \n",
    "    if 'stapler' in str(ckpt_path):\n",
    "        cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt == 3] = 2\n",
    "    if 'oven' in str(ckpt_path):\n",
    "        cur_gt[(cur_gt < 9) & (cur_gt > 1)] = 1\n",
    "        cur_gt[cur_gt == 9] = 2\n",
    "    if P(test_dataset.root_dir).parent.name == 'storage':\n",
    "        cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt == 2] = 1\n",
    "        cur_gt[cur_gt == 3] = 1\n",
    "        cur_gt[cur_gt == 4] = 2\n",
    "        cur_gt[cur_gt == 5] = 1\n",
    "    if P(test_dataset.root_dir).parent.name == 'box':\n",
    "        # cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        # cur_gt[cur_gt == 3] = 2\n",
    "        cur_gt[cur_gt == 4] = 2\n",
    "    cur_gt[cur_gt < 0] = 0\n",
    "    seg_classes[cur_gt == 0] = 0\n",
    "    valid_pred = seg_classes[cur_gt != 0].view(-1)\n",
    "    valid_gt = cur_gt[cur_gt != 0].to(valid_pred).view(-1)\n",
    "    tp = (valid_pred == valid_gt).sum()\n",
    "    valid_sum = valid_gt.shape[0]\n",
    "    iou = tp/valid_sum\n",
    "    ious += [iou]\n",
    "    pred_seg_img = seg_classes.view(800, 800).cpu().numpy()\n",
    "    gt_seg_img = cur_gt.view(800, 800).cpu().numpy()\n",
    "    plt.imsave(test_img_name, cmap[pred_seg_img.astype(np.int16)])\n",
    "    plt.imsave(gt_img, cmap[gt_seg_img.astype(np.int16)])\n",
    "ious = torch.stack(ious)\n",
    "\n",
    "std, mean = torch.std_mean(ious, dim=0)\n",
    "print(f'mean: {mean.item()}, std: {std.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save segmentation results for stapler\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:42<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9844302535057068, std: 0.002639641985297203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = glasses_path\n",
    "\n",
    "config_file = ckpt_path / 'eval' / 'config.json'\n",
    "config_argv = ['--config', str(config_file)]\n",
    "opts = get_opts(config_argv)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "setattr(opts, 'device', device)\n",
    "\n",
    "color_map = plt.get_cmap('Set3', 5)\n",
    "cmap = color_map.colors[:, :3]\n",
    "cmap[0, :] = 0\n",
    "\n",
    "opts.pre_trained_weights = str(ckpt_path / 'ckpt' / 'best_ckpt.pth')\n",
    "if opts.state == 'start':\n",
    "    opts.state = 'end'\n",
    "else:\n",
    "    opts.state = 'start'\n",
    "model = NGP_Prop_Art_Seg_Wrapper(config=opts, training=False, \n",
    "                                ignore_empty=False, use_timestamp=True, use_se3=opts.use_se3, mkdir=False)\n",
    "test_dir = model.output_path / 'test'\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "test_dataset = SapienParisDataset(\n",
    "        root_dir = opts.root_dir,\n",
    "        near = opts.near_plane,\n",
    "        far = opts.far_plane,\n",
    "        img_wh = opts.img_wh, \n",
    "        batch_size=opts.batch_size,\n",
    "        split='test',\n",
    "        render_bkgd='white',\n",
    "        state=opts.state\n",
    "    )\n",
    "\n",
    "ious = []\n",
    "for p in model.pose_module_list:\n",
    "    p.init_param()\n",
    "for idx in tqdm(range(test_dataset.poses.shape[0])):\n",
    "    batch_data = test_dataset.__getitem__(idx)\n",
    "    render_batch = model.test(batch_data)\n",
    "    seg_pred = render_batch['seg_label']\n",
    "    seg_bg = torch.ones_like(seg_pred[:, :, 0:1])\n",
    "    seg_bg = seg_bg - seg_pred.sum(dim=-1, keepdim=True)\n",
    "    seg_pred_bg = torch.cat([seg_bg, seg_pred], dim=-1)\n",
    "    seg_classes = torch.argmax(seg_pred_bg, dim=-1, keepdim=True)\n",
    "    seg_classes_np = seg_classes.cpu().numpy()\n",
    "    test_img_name = str(test_dir / (str(idx).zfill(4) + '.png'))\n",
    "    \n",
    "    # np.save(test_seg_name, seg_classes_np)\n",
    "    gt_img = str(test_dir / (str(idx).zfill(4) + '_gt.png'))\n",
    "    cur_gt = test_dataset.seg[idx] * 255\n",
    "    \n",
    "    if 'stapler' in str(ckpt_path):\n",
    "        cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt == 3] = 2\n",
    "    if 'oven' in str(ckpt_path):\n",
    "        cur_gt[(cur_gt < 9) & (cur_gt > 1)] = 1\n",
    "        cur_gt[cur_gt == 9] = 2\n",
    "    if P(test_dataset.root_dir).parent.name == 'storage':\n",
    "        cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt == 2] = 1\n",
    "        cur_gt[cur_gt == 3] = 1\n",
    "        cur_gt[cur_gt == 4] = 2\n",
    "        cur_gt[cur_gt == 5] = 1\n",
    "    if P(test_dataset.root_dir).parent.name == 'box':\n",
    "        # cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        # cur_gt[cur_gt == 3] = 2\n",
    "        cur_gt[cur_gt == 4] = 2\n",
    "    if P(test_dataset.root_dir).parent.name == 'glasses':\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        cur_gt[cur_gt==3] = 2\n",
    "        cur_gt[cur_gt==4] = 3\n",
    "        \n",
    "    cur_gt[cur_gt < 0] = 0\n",
    "    seg_classes[cur_gt == 0] = 0\n",
    "    valid_pred = seg_classes[cur_gt != 0].view(-1)\n",
    "    valid_gt = cur_gt[cur_gt != 0].to(valid_pred).view(-1)\n",
    "    tp = (valid_pred == valid_gt).sum()\n",
    "    valid_sum = valid_gt.shape[0]\n",
    "    iou = tp/valid_sum\n",
    "    ious += [iou]\n",
    "    pred_seg_img = seg_classes.view(800, 800).cpu().numpy()\n",
    "    gt_seg_img = cur_gt.view(800, 800).cpu().numpy()\n",
    "    plt.imsave(test_img_name, cmap[pred_seg_img.astype(np.int16)])\n",
    "    plt.imsave(gt_img, cmap[gt_seg_img.astype(np.int16)])\n",
    "ious = torch.stack(ious)\n",
    "\n",
    "std, mean = torch.std_mean(ious, dim=0)\n",
    "print(f'mean: {mean.item()}, std: {std.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oven_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:53<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9869259595870972, std: 0.007746274583041668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = oven_mp_path\n",
    "\n",
    "config_file = ckpt_path / 'eval' / 'config.json'\n",
    "config_argv = ['--config', str(config_file)]\n",
    "opts = get_opts(config_argv)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "setattr(opts, 'device', device)\n",
    "\n",
    "color_map = plt.get_cmap('Set3', 5)\n",
    "cmap = color_map.colors[:, :3]\n",
    "cmap[0, :] = 0\n",
    "\n",
    "opts.pre_trained_weights = str(ckpt_path / 'ckpt' / 'best_ckpt.pth')\n",
    "if opts.state == 'start':\n",
    "    opts.state = 'end'\n",
    "else:\n",
    "    opts.state = 'start'\n",
    "model = NGP_Prop_Art_Seg_Wrapper(config=opts, training=False, \n",
    "                                ignore_empty=False, use_timestamp=True, use_se3=opts.use_se3, mkdir=False)\n",
    "test_dir = model.output_path / 'test'\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "test_dataset = SapienParisDataset(\n",
    "        root_dir = opts.root_dir,\n",
    "        near = opts.near_plane,\n",
    "        far = opts.far_plane,\n",
    "        img_wh = opts.img_wh, \n",
    "        batch_size=opts.batch_size,\n",
    "        split='test',\n",
    "        render_bkgd='white',\n",
    "        state=opts.state\n",
    "    )\n",
    "\n",
    "ious = []\n",
    "for p in model.pose_module_list:\n",
    "    p.init_param()\n",
    "for idx in tqdm(range(test_dataset.poses.shape[0])):\n",
    "    batch_data = test_dataset.__getitem__(idx)\n",
    "    render_batch = model.test(batch_data)\n",
    "    seg_pred = render_batch['seg_label']\n",
    "    seg_bg = torch.ones_like(seg_pred[:, :, 0:1])\n",
    "    seg_bg = seg_bg - seg_pred.sum(dim=-1, keepdim=True)\n",
    "    seg_pred_bg = torch.cat([seg_bg, seg_pred], dim=-1)\n",
    "    seg_classes = torch.argmax(seg_pred_bg, dim=-1, keepdim=True)\n",
    "    seg_classes_np = seg_classes.cpu().numpy()\n",
    "    test_img_name = str(test_dir / (str(idx).zfill(4) + '.png'))\n",
    "    \n",
    "    # np.save(test_seg_name, seg_classes_np)\n",
    "    gt_img = str(test_dir / (str(idx).zfill(4) + '_gt.png'))\n",
    "    cur_gt = test_dataset.seg[idx] * 255\n",
    "    \n",
    "    if 'stapler' in str(ckpt_path):\n",
    "        cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt == 3] = 2\n",
    "    # if 'oven' in str(ckpt_path):\n",
    "    if P(test_dataset.root_dir).parent.name == 'oven':\n",
    "        cur_gt[(cur_gt < 9) & (cur_gt > 1)] = 1\n",
    "        cur_gt[cur_gt == 9] = 2\n",
    "    if P(test_dataset.root_dir).parent.name == 'storage':\n",
    "        cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt == 2] = 1\n",
    "        cur_gt[cur_gt == 3] = 1\n",
    "        cur_gt[cur_gt == 4] = 2\n",
    "        cur_gt[cur_gt == 5] = 1\n",
    "    if P(test_dataset.root_dir).parent.name == 'box':\n",
    "        # cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        # cur_gt[cur_gt == 3] = 2\n",
    "        cur_gt[cur_gt == 4] = 2\n",
    "    if P(test_dataset.root_dir).parent.name == 'glasses':\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        cur_gt[cur_gt==3] = 2\n",
    "        cur_gt[cur_gt==4] = 3\n",
    "    if P(test_dataset.root_dir).parent.name == 'oven_mp':\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        # cur_gt[cur_gt==3] = 2\n",
    "        cur_gt[cur_gt==4] = 2\n",
    "        cur_gt[cur_gt>3] = 1\n",
    "    cur_gt[cur_gt < 0] = 0\n",
    "    seg_classes[cur_gt == 0] = 0\n",
    "    valid_pred = seg_classes[cur_gt != 0].view(-1)\n",
    "    valid_gt = cur_gt[cur_gt != 0].to(valid_pred).view(-1)\n",
    "    tp = (valid_pred == valid_gt).sum()\n",
    "    valid_sum = valid_gt.shape[0]\n",
    "    iou = tp/valid_sum\n",
    "    ious += [iou]\n",
    "    pred_seg_img = seg_classes.view(800, 800).cpu().numpy()\n",
    "    gt_seg_img = cur_gt.view(800, 800).cpu().numpy()\n",
    "    plt.imsave(test_img_name, cmap[pred_seg_img.astype(np.int16)])\n",
    "    plt.imsave(gt_img, cmap[gt_seg_img.astype(np.int16)])\n",
    "ious = torch.stack(ious)\n",
    "\n",
    "std, mean = torch.std_mean(ious, dim=0)\n",
    "print(f'mean: {mean.item()}, std: {std.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 3., 4.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_gt.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_folder = ckpt_path / 'ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/dj/Downloads/project/nerfacc_ngp/results_stable/stapler_end_to_start_f16/1713970094/ckpt/002000.pth'),\n",
       " PosixPath('/home/dj/Downloads/project/nerfacc_ngp/results_stable/stapler_end_to_start_f16/1713970094/ckpt/004000.pth'),\n",
       " PosixPath('/home/dj/Downloads/project/nerfacc_ngp/results_stable/stapler_end_to_start_f16/1713970094/ckpt/006000.pth'),\n",
       " PosixPath('/home/dj/Downloads/project/nerfacc_ngp/results_stable/stapler_end_to_start_f16/1713970094/ckpt/008000.pth'),\n",
       " PosixPath('/home/dj/Downloads/project/nerfacc_ngp/results_stable/stapler_end_to_start_f16/1713970094/ckpt/best_ckpt.pth'),\n",
       " PosixPath('/home/dj/Downloads/project/nerfacc_ngp/results_stable/stapler_end_to_start_f16/1713970094/ckpt/010000.pth')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ckpt_folder.glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storage MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:42<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.9425734877586365, std: 0.03102875128388405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "storage_mp_path = P(\"/home/dj/Downloads/project/nerfacc_ngp/results_stable/storage_mp_start_to_end_f16/1713527878\")\n",
    "\n",
    "ckpt_path = storage_mp_path\n",
    "config_file = ckpt_path / 'eval' / 'config.json'\n",
    "config_argv = ['--config', str(config_file)]\n",
    "opts = get_opts(config_argv)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "setattr(opts, 'device', device)\n",
    "\n",
    "color_map = plt.get_cmap('Set3', 5)\n",
    "cmap = color_map.colors[:, :3]\n",
    "cmap[0, :] = 0\n",
    "\n",
    "opts.pre_trained_weights = str(ckpt_path / 'ckpt' / 'best_ckpt.pth')\n",
    "if opts.state == 'start':\n",
    "    opts.state = 'end'\n",
    "else:\n",
    "    opts.state = 'start'\n",
    "model = NGP_Prop_Art_Seg_Wrapper(config=opts, training=False, \n",
    "                                ignore_empty=False, use_timestamp=True, use_se3=opts.use_se3, mkdir=False)\n",
    "test_dir = model.output_path / 'test'\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "test_dataset = SapienParisDataset(\n",
    "        root_dir = opts.root_dir,\n",
    "        near = opts.near_plane,\n",
    "        far = opts.far_plane,\n",
    "        img_wh = opts.img_wh, \n",
    "        batch_size=opts.batch_size,\n",
    "        split='test',\n",
    "        render_bkgd='white',\n",
    "        state=opts.state\n",
    "    )\n",
    "\n",
    "ious = []\n",
    "for p in model.pose_module_list:\n",
    "    p.init_param()\n",
    "for idx in tqdm(range(test_dataset.poses.shape[0])):\n",
    "    batch_data = test_dataset.__getitem__(idx)\n",
    "    render_batch = model.test(batch_data)\n",
    "    seg_pred = render_batch['seg_label']\n",
    "    seg_bg = torch.ones_like(seg_pred[:, :, 0:1])\n",
    "    seg_bg = seg_bg - seg_pred.sum(dim=-1, keepdim=True)\n",
    "    seg_pred_bg = torch.cat([seg_bg, seg_pred], dim=-1)\n",
    "    seg_classes = torch.argmax(seg_pred_bg, dim=-1, keepdim=True)\n",
    "    seg_classes_np = seg_classes.cpu().numpy()\n",
    "    test_img_name = str(test_dir / (str(idx).zfill(4) + '.png'))\n",
    "    \n",
    "    # np.save(test_seg_name, seg_classes_np)\n",
    "    gt_img = str(test_dir / (str(idx).zfill(4) + '_gt.png'))\n",
    "    cur_gt = test_dataset.seg[idx] * 255\n",
    "    \n",
    "    if P(test_dataset.root_dir).parent.name ==  'stapler':\n",
    "        cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt == 3] = 2\n",
    "    # if 'oven' in str(ckpt_path):\n",
    "    if P(test_dataset.root_dir).parent.name == 'oven':\n",
    "        cur_gt[(cur_gt < 9) & (cur_gt > 1)] = 1\n",
    "        cur_gt[cur_gt == 9] = 2\n",
    "    if P(test_dataset.root_dir).parent.name == 'storage':\n",
    "        cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt == 2] = 1\n",
    "        cur_gt[cur_gt == 3] = 1\n",
    "        cur_gt[cur_gt == 4] = 2\n",
    "        cur_gt[cur_gt == 5] = 1\n",
    "    if P(test_dataset.root_dir).parent.name == 'box':\n",
    "        # cur_gt = cur_gt - 1\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        # cur_gt[cur_gt == 3] = 2\n",
    "        cur_gt[cur_gt == 4] = 2\n",
    "    if P(test_dataset.root_dir).parent.name == 'glasses':\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        cur_gt[cur_gt==3] = 2\n",
    "        cur_gt[cur_gt==4] = 3\n",
    "    if P(test_dataset.root_dir).parent.name == 'oven_mp':\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        # cur_gt[cur_gt==3] = 2\n",
    "        cur_gt[cur_gt==4] = 2\n",
    "        cur_gt[cur_gt>3] = 1\n",
    "    if P(test_dataset.root_dir).parent.name == 'storage_mp':\n",
    "        cur_gt[cur_gt==2] = 1\n",
    "        cur_gt[cur_gt==3] = 2\n",
    "        cur_gt[cur_gt==4] = 3\n",
    "        cur_gt[cur_gt>3] = 1\n",
    "    cur_gt[cur_gt < 0] = 0\n",
    "    seg_classes[cur_gt == 0] = 0\n",
    "    valid_pred = seg_classes[cur_gt != 0].view(-1)\n",
    "    valid_gt = cur_gt[cur_gt != 0].to(valid_pred).view(-1)\n",
    "    tp = (valid_pred == valid_gt).sum()\n",
    "    valid_sum = valid_gt.shape[0]\n",
    "    iou = tp/valid_sum\n",
    "    ious += [iou]\n",
    "    pred_seg_img = seg_classes.view(800, 800).cpu().numpy()\n",
    "    gt_seg_img = cur_gt.view(800, 800).cpu().numpy()\n",
    "    plt.imsave(test_img_name, cmap[pred_seg_img.astype(np.int16)])\n",
    "    plt.imsave(gt_img, cmap[gt_seg_img.astype(np.int16)])\n",
    "ious = torch.stack(ious)\n",
    "\n",
    "std, mean = torch.std_mean(ious, dim=0)\n",
    "print(f'mean: {mean.item()}, std: {std.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_gt.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "art_ngp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
